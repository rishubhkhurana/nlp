{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SimpleSentiment.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Do15S-gbY6F6",
        "yPFpLXncKpD3",
        "zciRCpK0ObKf",
        "t_nrJyTJPuuy",
        "du1V3lPIWyXE"
      ],
      "authorship_tag": "ABX9TyMQclNmUu8A6vpVQOl9ecZG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rishubhkhurana/nlp/blob/main/sentiment/SimpleSentiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqeMngTAKjeY"
      },
      "source": [
        "## Simple sentiment classifier\n",
        "\n",
        "1. Pretrained embedding\n",
        "\n",
        "2. LSTM layers -- 3\n",
        "\n",
        "3. All bi-directional layers\n",
        "\n",
        "4. packed padded sequences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Do15S-gbY6F6"
      },
      "source": [
        "## BookKeeping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5kGwSPkbY7cb",
        "outputId": "e41e4186-30c7-47f9-acb6-1a94c26ae60b"
      },
      "source": [
        "!pip install GPUtil"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting GPUtil\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
            "Building wheels for collected packages: GPUtil\n",
            "  Building wheel for GPUtil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for GPUtil: filename=GPUtil-1.4.0-cp36-none-any.whl size=7411 sha256=c938cbe32f95d1c54cf458ff24418fad8dc46c16a6bceb41e0ea63dc12852120\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
            "Successfully built GPUtil\n",
            "Installing collected packages: GPUtil\n",
            "Successfully installed GPUtil-1.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPFpLXncKpD3"
      },
      "source": [
        "## Importing Libs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QuH1XhsgKmQ_"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision.transforms import ToTensor\n",
        "import torchtext\n",
        "from torchtext.data import Field,LabelField\n",
        "from torchtext.datasets import IMDB\n",
        "from torchtext import data\n",
        "from torch.nn.utils.rnn import pack_padded_sequence,pad_packed_sequence\n",
        "import random\n",
        "import torch.optim as optim\n",
        "from fastprogress import master_bar, progress_bar\n",
        "from GPUtil import showUtilization"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7HAQDUILECh"
      },
      "source": [
        "## Downloading Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grjPNvQ4LFLg"
      },
      "source": [
        "SEED=1234\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGNViS6lLTWF"
      },
      "source": [
        "TEXT = Field(tokenize='spacy',include_lengths=True)\n",
        "LABEL = LabelField(dtype=torch.float)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpvYfklDLi48"
      },
      "source": [
        "train_data,test_data = IMDB.splits(TEXT,LABEL)"
      ],
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2e44MGcyqDrT",
        "outputId": "c1c5c017-d855-48da-f8e6-677853d8beeb"
      },
      "source": [
        "print(' '.join(vars(train_data.examples[0]).get('text')))"
      ],
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A great storyline with a message . Joan Plowright is superb as \" Phoebe \" , Mike Kopsa is hilarious as \" coach \" and Richard de Klerk plays the role of \" Carmine \" superbly . Mischa Barton as \" Frankie \" puts in a good performance and Ingrid as \" Hazel \" plays her first lead extremely well . This film is superbly directed by Jo - Beth Williams . The editing is first rate .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0RMZbyWp8em"
      },
      "source": [
        "# reverse the data\n",
        "for i in range(len(train_data)):\n",
        "    vars(train_data.examples[i]).get('text').reverse()"
      ],
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3obhDw7qf0Y",
        "outputId": "eec27fdb-e254-4264-e0a2-09b9181f2803"
      },
      "source": [
        "print(' '.join(vars(train_data.examples[0]).get('text')))"
      ],
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ". rate first is editing The . Williams Beth - Jo by directed superbly is film This . well extremely lead first her plays \" Hazel \" as Ingrid and performance good a in puts \" Frankie \" as Barton Mischa . superbly \" Carmine \" of role the plays Klerk de Richard and \" coach \" as hilarious is Kopsa Mike , \" Phoebe \" as superb is Plowright Joan . message a with storyline great A\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrqi55StLtE6",
        "outputId": "26635ae0-0827-47b7-dda9-20eefa9356f3"
      },
      "source": [
        "print(len(train_data),len(test_data))"
      ],
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25000 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1BuBRe1MiEM",
        "outputId": "e19f8662-d697-4567-b834-596cb7c0b4ae"
      },
      "source": [
        "print(vars(train_data.examples[0]))"
      ],
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'text': ['.', 'rate', 'first', 'is', 'editing', 'The', '.', 'Williams', 'Beth', '-', 'Jo', 'by', 'directed', 'superbly', 'is', 'film', 'This', '.', 'well', 'extremely', 'lead', 'first', 'her', 'plays', '\"', 'Hazel', '\"', 'as', 'Ingrid', 'and', 'performance', 'good', 'a', 'in', 'puts', '\"', 'Frankie', '\"', 'as', 'Barton', 'Mischa', '.', 'superbly', '\"', 'Carmine', '\"', 'of', 'role', 'the', 'plays', 'Klerk', 'de', 'Richard', 'and', '\"', 'coach', '\"', 'as', 'hilarious', 'is', 'Kopsa', 'Mike', ',', '\"', 'Phoebe', '\"', 'as', 'superb', 'is', 'Plowright', 'Joan', '.', 'message', 'a', 'with', 'storyline', 'great', 'A'], 'label': 'pos'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cX71ae2GMlTw"
      },
      "source": [
        "train_data,valid_data = train_data.split(random_state = random.seed(SEED))"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dfekoUaM0UI",
        "outputId": "8683eb0a-b10a-4589-b3d4-1d9bfcad23a4"
      },
      "source": [
        "len(train_data)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17500"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asNdyMagNgpa"
      },
      "source": [
        "## Data processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtYAdJ8xNXXX"
      },
      "source": [
        "MAX_VOCAB_SIZE = 25_000\n",
        "TEXT.build_vocab(train_data,max_size=MAX_VOCAB_SIZE, vectors = 'glove.6B.100d',unk_init = torch.Tensor.normal_)\n",
        "LABEL.build_vocab(train_data)"
      ],
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_nRB00UNvKU",
        "outputId": "e8bb9fe0-29b2-4452-e5e2-d94149222d71"
      },
      "source": [
        "print(len(TEXT.vocab))\n",
        "print(len(LABEL.vocab))"
      ],
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25002\n",
            "2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4fIOBtHNw13",
        "outputId": "27866630-c4d1-4673-a179-7b7ccf5570b3"
      },
      "source": [
        "print(TEXT.vocab.freqs.most_common(2))"
      ],
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('the', 289838), (',', 275296)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2m8SsxVN3eP",
        "outputId": "dc1b1752-5ff8-41c5-db50-60d60387017c"
      },
      "source": [
        "type(TEXT.vocab.freqs)"
      ],
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "collections.Counter"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_k2GG2DN5oB",
        "outputId": "2c72cd01-3bee-4cb3-c64c-f17d5b22c4ad"
      },
      "source": [
        "print(TEXT.vocab.itos[:10])"
      ],
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['<unk>', '<pad>', 'the', ',', '.', 'and', 'a', 'of', 'to', 'is']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1nkq6S6N_bI",
        "outputId": "b9debaf6-c741-4de0-9d57-239cb11f266f"
      },
      "source": [
        "print(LABEL.vocab.stoi)"
      ],
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "defaultdict(<function _default_unk_index at 0x7f4becbfa510>, {'neg': 0, 'pos': 1})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zciRCpK0ObKf"
      },
      "source": [
        "## Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeYR52xlOD-p"
      },
      "source": [
        "## data loaders\n",
        "BATCH_SIZE = 64\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "trn_dl, val_dl, test_dl = data.BucketIterator.splits((train_data,valid_data,test_data),batch_size=BATCH_SIZE, device = device, sort_within_batch=True)"
      ],
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_nrJyTJPuuy"
      },
      "source": [
        "## Model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64pQxAwWPvc-"
      },
      "source": [
        "class mLSTM(nn.Module):\n",
        "    def __init__(self,hidden_dims,embed_dims, vocab_size,output_dim, n_layers = 3, p = 0.2,padding_idx=1):\n",
        "        super().__init__()\n",
        "        self.embed = nn.Embedding(vocab_size,embed_dims,padding_idx=padding_idx)\n",
        "        self.n_layers = n_layers\n",
        "        self.rnn = nn.ModuleList()\n",
        "        for i in range(n_layers):\n",
        "            self.rnn.append(nn.LSTM(embed_dims if i==0 else 2*hidden_dims, hidden_dims,num_layers = 1,bidirectional = True))\n",
        "        self.dropout = nn.Dropout(p)\n",
        "        self.output_layer = nn.Linear(2*hidden_dims,output_dim)\n",
        "    \n",
        "    def forward(self,text,lengths):\n",
        "        # [seq_len,B]\n",
        "        embedded = self.embed(text)\n",
        "        # [seq_len,B,embed_dims]\n",
        "        packed_output = pack_padded_sequence(embedded,lengths.cpu())\n",
        "        for i,lyr in enumerate(self.rnn):\n",
        "            packed_output, (h,c) = lyr(packed_output)\n",
        "            padded_sequence,lengths = pad_packed_sequence(packed_output,padding_value=1)\n",
        "            padded_sequence = self.dropout(padded_sequence)\n",
        "            packed_output = pack_padded_sequence(padded_sequence,lengths.cpu())\n",
        "            #packed_output.data = self.dropout(packed_output.data)\n",
        "        # h --> [num_directions,B,hidden_dims]\n",
        "        out = self.dropout(torch.cat([h[-2,:,:],h[-1,:,:]],dim=1))\n",
        "        # out --> [B,2*hidden_dims]\n",
        "        out = self.output_layer(out)\n",
        "        return out\n"
      ],
      "execution_count": 206,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuQWP93DgjGB"
      },
      "source": [
        "model = mLSTM(256,100,len(TEXT.vocab),1,padding_idx = TEXT.vocab.stoi[TEXT.pad_token]).cuda()"
      ],
      "execution_count": 207,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "du1V3lPIWyXE"
      },
      "source": [
        "## Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4G9ltqkWzi2"
      },
      "source": [
        "class Accuracy(object):\n",
        "    def __init__(self,summable=True,reduce=True,logits=True):\n",
        "        self.reduce=True\n",
        "        self.summable=summable\n",
        "        self.logits=logits\n",
        "    def __call__(self,preds,targets):\n",
        "        if isinstance(preds,torch.Tensor):\n",
        "\n",
        "            if preds.shape[-1]>1:\n",
        "                preds = torch.argmax(preds,dim=-1)\n",
        "            else:\n",
        "                if self.logits:\n",
        "                    preds = torch.round(torch.sigmoid(preds))\n",
        "                else:\n",
        "                    preds = torch.round(preds)\n",
        "\n",
        "            return preds.eq(targets.view_as(preds)).float().mean()\n"
      ],
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pj58aOkW0m6"
      },
      "source": [
        "class Recorder(object):\n",
        "\n",
        "    def __init__(self,record_batch=True,record_epoch=True,track_loss=True,metric='accuracy'):\n",
        "        self.record_batch = record_batch\n",
        "        self.record_epoch = record_epoch\n",
        "        self.metric = metric\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.batch_stats = dict(losses=[],metrics=[])\n",
        "        self.epoch_stats = dict(losses=[],metrics=[])\n",
        "        self.batch_count = []\n",
        "\n",
        "    def update_batch(self,loss,metric,batch_size):\n",
        "        self.batch_stats['losses'].append(loss)\n",
        "        self.batch_stats['metrics'].append(metric)\n",
        "        self.batch_count.append(batch_size)\n",
        "    \n",
        "    def update_epoch(self):\n",
        "        n_batches = len(self.batch_count)\n",
        "        epoch_loss = sum([loss*bs for loss,bs in zip(self.batch_stats['losses'][-n_batches:],self.batch_count)])/sum(self.batch_count)\n",
        "        epoch_metric = sum([metric*bs for metric,bs in zip(self.batch_stats['metrics'][-n_batches:],self.batch_count)])/sum(self.batch_count)\n",
        "        self.epoch_stats['losses'].append(epoch_loss)\n",
        "        self.epoch_stats['metrics'].append(epoch_metric)\n",
        "        if not self.record_batch:\n",
        "            self.batch_stats = dict(losses=[],metrics=[])\n",
        "        self.batch_count=[]\n",
        "    \n",
        "    def get_epoch_stats(self):\n",
        "        return_str = f'Loss: {self.epoch_stats[\"losses\"][-1]:.3f}, {self.metric.capitalize()}: {self.epoch_stats[\"metrics\"][-1]:.3f}'\n",
        "        return return_str\n",
        "\n",
        "def one_batch(model,opt,loss_func,batch,device='cpu',train=True,metric_func=None):        \n",
        "    xb,yb = batch.text,batch.label\n",
        "    if not isinstance(xb,(list,tuple)):\n",
        "        xb=[xb]\n",
        "    xb,yb = [t.to(device) for t in xb],yb.to(device)\n",
        "    preds = model(*xb)\n",
        "    if isinstance(loss_func,nn.CrossEntropyLoss):\n",
        "        loss = loss_func(preds,yb)\n",
        "    else:\n",
        "        loss = loss_func(preds.view_as(yb),yb)\n",
        "    if train:\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        opt.zero_grad()\n",
        "    if metric_func is not None:\n",
        "        metric = metric_func(preds.cpu(),yb.cpu())\n",
        "    else:\n",
        "        metric = None\n",
        "    return loss.cpu().item(),metric.cpu().item()\n",
        "\n",
        "def trainEpoch(model,opt,loss_func,dl,device='cpu',recorder=None,metric_func=None, parent=None): \n",
        "    if recorder is None:\n",
        "        raise RuntimeError(\"Please pass the recorder\")\n",
        "    # training the model\n",
        "    pb = progress_bar(dl,total=len(dl),parent=parent)\n",
        "    for batch in pb:\n",
        "        loss,metric = one_batch(model,opt,loss_func,batch,device=device,train=True,metric_func=metric_func)\n",
        "        parent.child.comment = f'Loss: {loss:.3f}, {metric_func.__class__.__name__}: {metric:.3f}'\n",
        "        recorder.update_batch(loss,metric,batch.label.shape[0])\n",
        "        del batch\n",
        "\n",
        "def evalEpoch(model,opt,loss_func,dl,device='cpu',recorder=None,metric_func=None, parent=None): \n",
        "    if recorder is None:\n",
        "        raise RuntimeError(\"Please pass the recorder\")\n",
        "    #evaluating the model\n",
        "    with torch.no_grad():\n",
        "        pb = progress_bar(dl,total=len(dl),parent=parent)\n",
        "        for batch in pb:\n",
        "            loss,metric = one_batch(model,opt,loss_func,batch,device=device,train=False,metric_func=metric_func)\n",
        "            parent.child.comment = f'Loss: {loss:.3f}, {metric_func.__class__.__name__}: {metric:.3f}'\n",
        "            recorder.update_batch(loss,metric,batch.label.shape[0])\n",
        "\n",
        "def testEpoch(model,opt,loss_func,dl,device='cpu',recorder=None,metric_func=None, parent=None): \n",
        "    if recorder is None:\n",
        "        raise RuntimeError(\"Please pass the recorder\")\n",
        "    # evaluating the model\n",
        "    with torch.no_grad():\n",
        "        pb = progress_bar(dl,total=len(dl),parent=parent)\n",
        "        for batch in pb:\n",
        "            loss,metric = one_batch(model,opt,oss_func,batch,device=device,train=False)\n",
        "            recorder.update_batch(loss,metric,batch.label.shape[0])\n",
        "\n",
        "            \n",
        "def trainModel(model,opt,loss_func,dls,NEpochs=50,device='cpu',metric_func=None):\n",
        "    if metric_func is None:\n",
        "        raise RuntimeError(\"Please pass the metric function\")\n",
        "    mb = master_bar(range(NEpochs),total=NEpochs)\n",
        "    trainRecorder = Recorder()\n",
        "    valRecorder = Recorder()\n",
        "    #trainRecorder = None\n",
        "    #valRecorder = None\n",
        "    for epoch in mb:\n",
        "        model.train()\n",
        "        trainEpoch(model,opt,loss_func,dls['train'],device=device,metric_func=metric_func,parent=mb,recorder = trainRecorder)\n",
        "        model.eval()\n",
        "        evalEpoch(model,opt,loss_func,dls['valid'],device=device,metric_func=metric_func,parent=mb,recorder = valRecorder)\n",
        "        trainRecorder.update_epoch()\n",
        "        valRecorder.update_epoch()\n",
        "        mb.write(f'Epoch[{epoch}]--> Training Stats: {trainRecorder.get_epoch_stats()}, Validation Stats: {valRecorder.get_epoch_stats()}')\n",
        "        print(showUtilization())\n",
        "    return trainRecorder,valRecorder\n",
        "\n",
        "def testModel(model,opt,loss_func,dls,NEpochs=50,device='cpu',metric_func=None):\n",
        "    if metric_func is None:\n",
        "        raise RuntimeError(\"Please pass the metric function\")\n",
        "    testRecorder = Recorder()\n",
        "    model.eval()\n",
        "    mb = master_bar(range(NEpochs),total=1)\n",
        "    for epoch in mb:\n",
        "        evalEpoch(model,opt,loss_func,dls['test'],device=device,metric_func=metric_func,parent=mb,recorder = testRecorder)\n",
        "        mb.write(f'Epoch[{epoch}]--> Testing Stats: {testRecorder.get_epoch_stats()}')\n",
        "    \n",
        "    return testRecorder\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJWW4sXvXG_U"
      },
      "source": [
        "## Training Simple model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yK5RVQqcX3TX"
      },
      "source": [
        "model_params = {}\n",
        "model_params['hidden_dims'] = 256\n",
        "model_params['vocab_size'] = len(TEXT.vocab)\n",
        "model_params['output_dim'] = 1\n",
        "model_params['embed_dims'] = 100\n",
        "model_params['padding_idx'] = TEXT.vocab.stoi[TEXT.pad_token]\n",
        "model_params['p'] = 0.2\n",
        "model_params['n_layers'] = 3\n",
        "model = mLSTM(**model_params).to('cuda')\n"
      ],
      "execution_count": 208,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O56JhNqYlCg-"
      },
      "source": [
        "\n",
        "model.embed.weight.data.copy_(TEXT.vocab.vectors)\n",
        "model.embed.weight.data[TEXT.vocab.stoi[TEXT.pad_token]] = torch.zeros(model_params['embed_dims'])\n",
        "model.embed.weight.data[TEXT.vocab.stoi[TEXT.unk_token]] = torch.zeros(model_params['embed_dims'])"
      ],
      "execution_count": 209,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHFTxVj-lhbu",
        "outputId": "06e49efb-2643-425b-d1ad-b2b536d38f20"
      },
      "source": [
        "model.embed.weight.data"
      ],
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n",
              "        ...,\n",
              "        [ 0.9012,  0.7192,  1.2343,  ..., -1.6855,  0.7152, -0.7761],\n",
              "        [ 0.0210,  2.1859,  0.2976,  ..., -0.9113,  0.0041,  0.2354],\n",
              "        [-0.4992,  1.0342,  0.4681,  ...,  0.9418, -1.5903,  1.2315]],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 210
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BC0BRdipXIia"
      },
      "source": [
        "opt = optim.Adam(model.parameters())\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "dls = {'train':trn_dl,'valid':val_dl,'test':test_dl}\n",
        "metric_func = Accuracy()"
      ],
      "execution_count": 211,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "id": "DM4LV3_UYHgg",
        "outputId": "4da13bad-3c67-41bf-e657-707608d9e877"
      },
      "source": [
        "trecorder, vrecorders = trainModel(model,opt,criterion,dls,device='cuda',metric_func=metric_func,NEpochs=5)"
      ],
      "execution_count": 212,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Epoch[0]--> Training Stats: Loss: 0.598, Accuracy: 0.669, Validation Stats: Loss: 0.460, Accuracy: 0.787<p>Epoch[1]--> Training Stats: Loss: 0.360, Accuracy: 0.848, Validation Stats: Loss: 0.371, Accuracy: 0.843<p>Epoch[2]--> Training Stats: Loss: 0.260, Accuracy: 0.899, Validation Stats: Loss: 0.247, Accuracy: 0.905<p>Epoch[3]--> Training Stats: Loss: 0.204, Accuracy: 0.923, Validation Stats: Loss: 0.218, Accuracy: 0.920<p>Epoch[4]--> Training Stats: Loss: 0.163, Accuracy: 0.943, Validation Stats: Loss: 0.189, Accuracy: 0.930"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "| ID | GPU | MEM |\n",
            "------------------\n",
            "|  0 | 56% | 70% |\n",
            "None\n",
            "| ID | GPU | MEM |\n",
            "------------------\n",
            "|  0 | 54% | 70% |\n",
            "None\n",
            "| ID | GPU | MEM |\n",
            "------------------\n",
            "|  0 | 87% | 70% |\n",
            "None\n",
            "| ID | GPU | MEM |\n",
            "------------------\n",
            "|  0 | 32% | 70% |\n",
            "None\n",
            "| ID | GPU | MEM |\n",
            "------------------\n",
            "|  0 | 45% | 70% |\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "86A04487z2XS",
        "outputId": "a149b283-a317-4fe7-d633-942e586659fc"
      },
      "source": [
        "vrecorders.get_epoch_stats()"
      ],
      "execution_count": 213,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Loss: 0.189, Accuracy: 0.930'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 213
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xt-aWoqvzfTz"
      },
      "source": [
        "def binary_accuracy(preds, y):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "\n",
        "    #round predictions to the closest integer\n",
        "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "    correct = (rounded_preds == y).float() #convert into float for division \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc"
      ],
      "execution_count": 214,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXBivcnrzTAz"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "\n",
        "            text, text_lengths = batch.text\n",
        "            \n",
        "            predictions = model(text, text_lengths).squeeze(1)\n",
        "            \n",
        "            loss = criterion(predictions, batch.label)\n",
        "            \n",
        "            acc = binary_accuracy(predictions, batch.label)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 215,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SeT_KpRKzTwE",
        "outputId": "ff2f7f20-4c4e-493a-f471-ab31be59b1ed"
      },
      "source": [
        "test_loss, test_acc = evaluate(model, dls['test'], criterion)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ],
      "execution_count": 216,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.378 | Test Acc: 85.54%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}